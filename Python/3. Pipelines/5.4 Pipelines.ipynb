{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.4 Pipelines.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fwHo1L6cWVH",
        "colab_type": "text"
      },
      "source": [
        "# Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL_r_h7FcWVJ",
        "colab_type": "text"
      },
      "source": [
        "Pipelines are sequences of \n",
        "transformers with an optional estimator at the end. \n",
        "\n",
        "The entire composite is:\n",
        "- a _transformer_ if it does not contain an estimator\n",
        "- an _estimator_ if the sequence ends with an estimator\n",
        "\n",
        "If a pipeline is:\n",
        "- a transformer, then it (the entire pipeline) has a `fit` method and a `transform` method\n",
        "- an estimator, then it (the entire pipeline) has a `fit` method and a `predict` method\n",
        "\n",
        "The work involved in understanding pipelines is in understanding how the above methods (of the pipeline) are composed of the `fit`, `transform` and `predict` methods of the transformers (and optional estimator) that make up the pipeline. \n",
        "\n",
        "This will be demonstrated below in two sections: __Transformer pipelines__ and __Estimator pipelines__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bv95M2hcWVL",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "- http://scikit-learn.org/stable/modules/pipeline.html\n",
        "- http://scikit-learn.org/stable/data_transforms.html\n",
        "- http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
        "- http://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction\n",
        "- http://scikit-learn.org/stable/modules/unsupervised_reduction.html#data-reduction\n",
        "- http://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH_XoQsDcWVL",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "1. Setup\n",
        "1. Transformer pipelines\n",
        "1. Estimator pipelines\n",
        "1. Pipelines with train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r18hLfWEcWVM",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsswgGDWcWVN",
        "colab_type": "text"
      },
      "source": [
        "Import the `pandas` and `numpy` libraries. In addition, import the `train_test_split` class with which we will create train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyuZp5AzcWVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas  as pd\n",
        "import numpy   as np\n",
        "import sklearn as sk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iglAPnELcWVT",
        "colab_type": "text"
      },
      "source": [
        "Display the version numbers of the numpy, pandas and scikit-learn packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ugC2olJcWVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('numpy  ',np.__version__)\n",
        "print('pandas ',pd.__version__)\n",
        "print('sklearn',sk.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGX-Tq1NcWVW",
        "colab_type": "text"
      },
      "source": [
        "Load the iris dataset to use in the demonstration below. Create datasets for features and the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxWt4Mn7cWVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_features = load_iris().data\n",
        "iris_target   = load_iris().target\n",
        "(iris_features.shape, \n",
        " iris_target.shape\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP20S_-ecWVZ",
        "colab_type": "text"
      },
      "source": [
        "Create train and test datasets from the feature and target datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abNd3PMRcWVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(iris_features, iris_target)\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIpFpdaScWVd",
        "colab_type": "text"
      },
      "source": [
        "The pipelines below are created with an `Imputer` object, a `MinMaxScaler` object and a `LogisticRegression` classifier object.\n",
        "For details see:\n",
        "- `Imputer`: https://bentley.cloud.databricks.com/#notebook/430288\n",
        "- `MinMaxScaler`: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
        "- `LogisticRegression`: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrYFa1dYcWVd",
        "colab_type": "text"
      },
      "source": [
        "## 2. Transformer pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTKZhnFkcWVe",
        "colab_type": "text"
      },
      "source": [
        "A transformer pipeline is sequence of transformers. (It does not contain an estimator.)\n",
        "\n",
        "For this demonstration the pipeline will consist of (in this order):\n",
        "1. An `Imputer` object that will complete the missing values\n",
        "2. A `MinMaxScaler` object that will rescale each column\n",
        "\n",
        "This pipeline is created below in `xfm_pipe`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHTYfKNgcWVf",
        "colab_type": "text"
      },
      "source": [
        "### `fit` and `transform`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNRl4mjKcWVf",
        "colab_type": "text"
      },
      "source": [
        "Create pipeline and individual transformers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEVcoXWxcWVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline      import Pipeline\n",
        "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
        "\n",
        "xfm = Pipeline([\n",
        "  ('imputer', Imputer(strategy=\"mean\")),\n",
        "  ('scaler',  MinMaxScaler())\n",
        "])\n",
        "imp = Imputer(strategy=\"mean\")\n",
        "sca = MinMaxScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBAzuM-pcWVk",
        "colab_type": "text"
      },
      "source": [
        "Fit and transform the `x_train` dataset on the individual transformers, in the same order as the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIZdEi1qcWVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_imp      = imp.fit(x_train)    .transform(x_train)\n",
        "x_train_imp_sca  = sca.fit(x_train_imp).transform(x_train_imp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjAuTXgacWVn",
        "colab_type": "text"
      },
      "source": [
        "Fit and transform the `x_train` dataset on the entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bkAUOHCcWVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xfm.fit(x_train)\n",
        "x_train_xfm = xfm.transform(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJIvJ-Y8cWVr",
        "colab_type": "text"
      },
      "source": [
        "Compare the results of these two methods. (They should be the same.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaaxvBajcWVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.all(x_train_imp_sca == x_train_xfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCK9FU8UcWVt",
        "colab_type": "text"
      },
      "source": [
        "They are the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRlIqiwrcWVu",
        "colab_type": "text"
      },
      "source": [
        "### `fit` only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBnXD51ncWVu",
        "colab_type": "text"
      },
      "source": [
        "Recreate the pipeline and individual transformers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBak005AcWVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline      import Pipeline\n",
        "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
        "\n",
        "xfm = Pipeline([\n",
        "  ('imputer', Imputer(strategy=\"mean\")),\n",
        "  ('scaler',  MinMaxScaler())\n",
        "])\n",
        "imp = Imputer(strategy=\"mean\")\n",
        "sca = MinMaxScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KcopOatcWVw",
        "colab_type": "text"
      },
      "source": [
        "Fit the `x_train` datasets to the individual transformers in the same order as the entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rBsgxVycWVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_imp      = imp.fit(x_train).transform(x_train)\n",
        "sca.fit(x_train_imp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Y9BNsicWV0",
        "colab_type": "text"
      },
      "source": [
        "Fit the `x_train` dataset on the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmckgQU_cWV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xfm.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx-1OJqgcWV2",
        "colab_type": "text"
      },
      "source": [
        "Compare the `data_range_` attribute from the last individual transformer and from the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5ouKPWZcWV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(sca                      .data_range_, \n",
        " xfm.named_steps['scaler'].data_range_\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic8iatBfcWV7",
        "colab_type": "text"
      },
      "source": [
        "They are the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kegqjfqcWV8",
        "colab_type": "text"
      },
      "source": [
        "### `transform` only (`x_train` has already been fit above)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch-4EYRkcWV9",
        "colab_type": "text"
      },
      "source": [
        "Transform the `x_test` datasets using the individual transformers in the same order as the entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pELnTRvecWV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_imp     = imp.transform(x_test)\n",
        "x_test_imp_sca = sca.transform(x_test_imp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAyTzrSPcWWC",
        "colab_type": "text"
      },
      "source": [
        "Transform the `x_test` datasets entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruDHftsGcWWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_xfm     = xfm.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JpcMEsGcWWF",
        "colab_type": "text"
      },
      "source": [
        "Check whether the two results are the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkWISUMAcWWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.all(x_test_imp_sca==x_test_xfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvfTGSDKcWWK",
        "colab_type": "text"
      },
      "source": [
        "They are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYeRzc3wcWWL",
        "colab_type": "text"
      },
      "source": [
        "## 3. Estimator pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHKcWGc5cWWM",
        "colab_type": "text"
      },
      "source": [
        "__TBD__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_B4v77acWWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline      import Pipeline\n",
        "from sklearn.linear_model  import LogisticRegression\n",
        "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
        "\n",
        "est = Pipeline([\n",
        "  ('imputer', Imputer(strategy=\"mean\")),\n",
        "  ('scaler',  MinMaxScaler()),\n",
        "  ('logreg',  LogisticRegression())\n",
        "])\n",
        "imp = Imputer(strategy=\"mean\")\n",
        "sca = MinMaxScaler()\n",
        "log = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH6mx8CmcWWP",
        "colab_type": "text"
      },
      "source": [
        "__The End__"
      ]
    }
  ]
}
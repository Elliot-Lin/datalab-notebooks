{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.0 Introduction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-space/datalab-notebooks/blob/master/Python/4.%20Workflows/1.0%20Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GoVnL7QRPGk",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Machine Learning Workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKTqMUFRPGp",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "\n",
        "Old references\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- https://scikit-learn.org/stable/datasets/index.html\n",
        "- https://machinelearningmastery.com/time-series-forecasting-supervised-learning/\n",
        "- https://machinelearningmastery.com/time-series-datasets-for-machine-learning/\n",
        "- https://plot.ly/python/time-series/\n",
        "- https://www.plotly.express/plotly_express/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCeZm-TwRPGq",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "1. Introduction\n",
        "1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GM-mxEURPGr",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UAfDppwRPG2",
        "colab_type": "text"
      },
      "source": [
        "Supervised machine learning has the general goal of creating a model/method to make _good_ predictions on unseen data. \n",
        "\n",
        "Machine learning workflows (for supervised learning) organize the steps that accompish this goal. These steps are:\n",
        "1. Get the initial dataset\n",
        "2. Create a feature-target dataset (from the initial datset)\n",
        "3. Create train and test datasets (from the feature-target dataset)\n",
        "4. Fit model (to the train dataset)\n",
        "5. Make and evaluate predictions (made by the fit model on the test dataset)\n",
        "\n",
        "There are four components (that you provide) as input to the workflow:\n",
        "1. The initial dataset\n",
        "2. The process to create the feature-target dataset\n",
        "3. The process to fit the model\n",
        "4. The choice of metric to use in evaluating the model predictions\n",
        "\n",
        "Our focus will be on the processes to prepare the data in step 2 and to fit the model in step 4. \n",
        "\n",
        "In this notebook, these steps will be described and implemented in Python code and run with two simple datasets. \n",
        "\n",
        "Later notebooks will implement this workflow with more involved datasets which will provide opprtunity to focus on steps 2 and 4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9UElX2S2Ap4",
        "colab_type": "text"
      },
      "source": [
        "There are a few requirements of the workflow. In general, information used to evaluate the model should not be available when creating the model. Specifically, \n",
        "- the train dataset should be used to fit the model\n",
        "- the test dataset should be used to evaluate the model\n",
        "- step 5 should only be run once\n",
        "- the feature-target dataset should be created using only per-row transformations and have predictor columns only of numeric types \n",
        "\n",
        "The first two requirements will be implemented in the code below. The last two requirements will be discussed in later notebooks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wfU4tsH5U5X",
        "colab_type": "text"
      },
      "source": [
        "The takeaways from this notebook are:\n",
        "- workflow steps\n",
        "- workflow components\n",
        "\n",
        "The requirements will be revisited in later notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoXXxsa5I7rI",
        "colab_type": "text"
      },
      "source": [
        "The __Setup__ section loads three libraries and displays their version numbers. Following this is a section for each of the workflow steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTcFuxVEFTaF",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxIsWumyRPGt",
        "colab_type": "text"
      },
      "source": [
        "Import the `pandas`,  `numpy` and `sklearn` libraries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iKsgHXpRPGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas  as pd\n",
        "import numpy   as np\n",
        "import sklearn as sk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_53LqmHxRPGy",
        "colab_type": "text"
      },
      "source": [
        "Display the version numbers of the numpy, pandas and scikit-learn packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVpiFs1MRPGz",
        "colab_type": "code",
        "outputId": "88c737da-5803-41ca-8759-5a0cf5237ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('numpy  :',np.__version__)\n",
        "print('pandas :',pd.__version__)\n",
        "print('sklearn:',sk.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy  : 1.16.4\n",
            "pandas : 0.24.2\n",
            "sklearn: 0.21.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrHTzAV_ivtk",
        "colab_type": "text"
      },
      "source": [
        "## Workflow steps (demonstration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FunnoU-vJqJf",
        "colab_type": "text"
      },
      "source": [
        "### Step 1. Get initial dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGyFIRu-TleL",
        "colab_type": "text"
      },
      "source": [
        "This step is implemented with a single Python function (`get_initial_data_pdf`) that reads data from its source and returns a pandas dataframe (`pdf`). The function for this example retrieves the iris dataset from the `sklearn.datasets` module and returns the features and target concatenated into a single dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4eL3gpmKt3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iris_pdf():\n",
        "  import pandas as pd\n",
        "  from sklearn.datasets import load_iris\n",
        "  iris_features     = load_iris().data\n",
        "  iris_target       = load_iris().target\n",
        "  iris_target_names = load_iris().target_names\n",
        "\n",
        "  iris_feature_columns = [feature_name.replace(' ','_')\n",
        "                                      .replace('(','')\n",
        "                                      .replace(')','') \n",
        "                          for feature_name in load_iris().get('feature_names')]\n",
        "  \n",
        "  iris_features_pdf = pd.DataFrame(data=iris_features,\n",
        "                                   columns=iris_feature_columns\n",
        "                                  )\n",
        "  iris_target_pdf = pd.DataFrame(data={'species': iris_target}) \\\n",
        "                      .replace(to_replace={n:iris_target_names[n]\n",
        "                                           for n in [0,1,2]}) \\\n",
        "                      .astype('object')\n",
        "  iris_pdf = pd.concat([iris_features_pdf, iris_target_pdf],\n",
        "                       axis='columns',\n",
        "                       join='inner')\n",
        "  return iris_pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBtVd7-jUxNI",
        "colab_type": "text"
      },
      "source": [
        "Notice that the column names have been changed to use snake case, the parentheses have been removed from the feature column names, and the target column has been named `species` and its values replaced with strings. \n",
        "\n",
        "Store the data frame in `initial_pdf` for input to the next step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w588FI7APVi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_pdf = get_iris_pdf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyBtirBmXsSp",
        "colab_type": "text"
      },
      "source": [
        "Notice that the datatypes look correct. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnHZi9_UUrrF",
        "colab_type": "code",
        "outputId": "55316973-3e20-431d-c154-d9b361a4c410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "initial_pdf.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            "sepal_length_cm    150 non-null float64\n",
            "sepal_width_cm     150 non-null float64\n",
            "petal_length_cm    150 non-null float64\n",
            "petal_width_cm     150 non-null float64\n",
            "species            150 non-null object\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 5.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG_mwcCvXzGh",
        "colab_type": "code",
        "outputId": "6af5e36a-2053-467a-9f20-cee4b32824a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "initial_pdf.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length_cm</th>\n",
              "      <th>sepal_width_cm</th>\n",
              "      <th>petal_length_cm</th>\n",
              "      <th>petal_width_cm</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm species\n",
              "0              5.1             3.5              1.4             0.2  setosa\n",
              "1              4.9             3.0              1.4             0.2  setosa\n",
              "2              4.7             3.2              1.3             0.2  setosa\n",
              "3              4.6             3.1              1.5             0.2  setosa\n",
              "4              5.0             3.6              1.4             0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPlDO6HNXjWU",
        "colab_type": "code",
        "outputId": "17bf1ca8-72e1-4779-a310-7b1d17cc8e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "initial_pdf['species'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "virginica     50\n",
              "setosa        50\n",
              "versicolor    50\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B7izFb6Xxqx",
        "colab_type": "text"
      },
      "source": [
        "The `get_iris_pdf` function returns a pandas dataframe with columns that have correct datatypes, which is the primary concern at this step. This dataframe will be passed to the next step, which creates a feature-target dataframe)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_SzjnpPJ4al",
        "colab_type": "text"
      },
      "source": [
        "### Step 2. Create feature-target dataframe by preprocessing initial dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g27AdQ5SZ8vd",
        "colab_type": "text"
      },
      "source": [
        "This step takes as input the initial dataframe produced by the previous step and returns a dataframe with a target variable and predictor variables. In general this step consists of only per row transformations of the initial dataframe, which __do not__ use aggregate data summarized across the entire dataframe. Later notebooks will focus on this constraint.\n",
        "\n",
        "In addition, it is essential that the target column does not include any missing values.\n",
        "\n",
        "In this example, the only work involved is to\n",
        "- drop rows where `species` is equal to `setosa`\n",
        "- rename the `species` column  to `target` \n",
        "\n",
        "Below this work is done by a _transformer object_ of class `IrisFeaTgtPDF` that is returned by the function `get_prepare_transformer_object`.  Using a transformer class doesn't seem useful now, but it will later when things get more complicated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWlin2Sgh7Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class IrisFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.loc[lambda pdf: pdf.species!='setosa'] \\\n",
        "            .rename(columns={'species':'target'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Qg9882Yu1i",
        "colab_type": "text"
      },
      "source": [
        "The `get_feature_target_pdf` function passes the pandas dataframe `pdf` to the `fit` and `transform` methods of the `transformer_object`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm4W3u-A3Y3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_target_pdf(pdf, transformer_object): \n",
        "  return transformer_object.fit(pdf).transform(pdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iEtngmsFuyN",
        "colab_type": "text"
      },
      "source": [
        "This function is called with the initial dataframe as input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyCMFjrv-jhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_target_pdf = get_feature_target_pdf(initial_pdf, \n",
        "                                            IrisFeaTgtPDF()\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvoGvInMPvPk",
        "colab_type": "code",
        "outputId": "ad7bfec0-5b38-45eb-c3a3-ff0cd5bc6ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "feature_target_pdf.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 100 entries, 50 to 149\n",
            "Data columns (total 5 columns):\n",
            "sepal_length_cm    100 non-null float64\n",
            "sepal_width_cm     100 non-null float64\n",
            "petal_length_cm    100 non-null float64\n",
            "petal_width_cm     100 non-null float64\n",
            "target             100 non-null object\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 4.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodYyUlRPzYM",
        "colab_type": "code",
        "outputId": "4f0674b6-fe12-48b6-b09e-958c484274cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "feature_target_pdf['target'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "virginica     50\n",
              "versicolor    50\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrjOlPXBJ6p1",
        "colab_type": "text"
      },
      "source": [
        "### Step 3. Create train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3xY_zleGfzV",
        "colab_type": "text"
      },
      "source": [
        "This is a simple, but important step in the process. The two steps, creating the model (step 4) and evaluating the model (step 5) must be use different datasets. Step 4 uses the train dataset and step 5 uses the test dataset. Otherwise there is no reason to believe that the results for predictions on unseen data would be similar to your results. In particular, \n",
        "- The model is created from the  train dataset\n",
        "- Predictions are made from the predictor variables of the test dataset\n",
        "- These predicitions will be compared to the target variable of the test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4lDyDtnri92",
        "colab_type": "text"
      },
      "source": [
        "The Scikit-learn library makes available the `train_test_split` function that creates train and test datasets. This function is _wrapped_ below to create a function that takes as input a dataframe and the name of the target variable and returns a dictionary of results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMEa41-EInnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_dict(pdf, target_name, **kwargs):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(pdf.drop(columns=target_name),\n",
        "                                                      pdf[target_name], \n",
        "                                                      **kwargs)\n",
        "  return {\n",
        "      'x_train': X_train,\n",
        "      'y_train': y_train,\n",
        "      'x_test' : X_test,\n",
        "      'y_test' : y_test\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKKXiL7J44S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_test_dict = get_train_test_dict(feature_target_pdf,'target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW8q8NjVax7X",
        "colab_type": "text"
      },
      "source": [
        "The function returns a dictionary with one key-value pair for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Srh38ZHQOZV",
        "colab_type": "code",
        "outputId": "5be9cc26-6961-4bd9-e1f5-c1cf06595ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_test_dict.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['x_train', 'y_train', 'x_test', 'y_test'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWhtg7eZa7_8",
        "colab_type": "text"
      },
      "source": [
        "Notice the differences in datatype and shape of the output. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBmJBSpHRSIS",
        "colab_type": "code",
        "outputId": "3db9ea9b-be4b-4483-bbb6-99a2e3d14435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "[(name, type(val), val.shape) for (name,val) in train_test_dict.items()]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('x_train', pandas.core.frame.DataFrame, (75, 4)),\n",
              " ('y_train', pandas.core.series.Series, (75,)),\n",
              " ('x_test', pandas.core.frame.DataFrame, (25, 4)),\n",
              " ('y_test', pandas.core.series.Series, (25,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhWL87NjJ8OQ",
        "colab_type": "text"
      },
      "source": [
        "### Step 4. Fit model \n",
        "\n",
        "A _model_ is _fit_ on a training dataset so that it (the fit model) can be used to make predictions on unseen datasets (that contain the same predictor columns as the training dataset). \n",
        "\n",
        "Linear regression and logistic regression are common models. When they are fit to a training dataset coefficients are determined for each predictor column/variable that are then used to make predictions from a row of values with values for these predictor variables.\n",
        "\n",
        "This is accomplished in Python using the Scikit-learn library with estimator objects that have `fit` and `predict` methods. The `fit` method takes as input the `x_train` of predictor dataframe and the `y_train` target series. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLCWMp6iRt2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fit_model(estimator_object, x_train, y_train):\n",
        "  return estimator_object.fit(X=x_train,\n",
        "                              y=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr6M-UMne6JQ",
        "colab_type": "text"
      },
      "source": [
        "The `get_fit_model` function (defined above) is called with transformer object `LogisticRegression()`  and with the predictor training dataframe and the target training series. The function returns the fit model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-_VJ7_KSet3",
        "colab_type": "code",
        "outputId": "94a2961c-f295-4037-8435-8dfc5f70ed43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "fit_model = get_fit_model(estimator_object=LogisticRegression(),\n",
        "                          x_train         =train_test_dict.get('x_train'),\n",
        "                          y_train         =train_test_dict.get('y_train'),\n",
        "                         )\n",
        "fit_model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVVIfr7hJ9-O",
        "colab_type": "text"
      },
      "source": [
        "### Step 5. Make and evaluate predictions \n",
        "\n",
        "After a model has been fit to the training datasets it can then be used to make predictions using the `predict` method. The `get_predict_ser` function takes as input a fit model and a predictor dataframe and returns a series of predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n_Ud0SZVIqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predict_ser(model, x_test):\n",
        "  return model.predict(X=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-EGtn3gPsi",
        "colab_type": "text"
      },
      "source": [
        "As the name of the `x_test` parameter suggests that parameter value should be the test predictor dataframe. As mentioned above, it is important to use different datasets for model evaluation (the test dataset) and for model fitting (the train dataset). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMN4cyKnubaW",
        "colab_type": "text"
      },
      "source": [
        "Create a pandas series of predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSAGYcBJZFrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "18ac8df4-56a6-4d29-dc49-aee7b9902902"
      },
      "source": [
        "predict_ser = get_predict_ser(model =fit_model, \n",
        "                              x_test=train_test_dict.get('x_test')\n",
        "                             )\n",
        "predict_ser[:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['versicolor', 'versicolor', 'virginica', 'versicolor', 'virginica'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMXG4V6RhOe6",
        "colab_type": "text"
      },
      "source": [
        "The `get_actual_predict_pdf` function (below) simply creates a dataframe with one column for actual values and one column for predicted values. In addition, the dataframe index is set to be the same as the index of the actual values (target test series). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "But2R3raWHKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_pdf(actual,predict):\n",
        "  import pandas as pd\n",
        "  return pd.DataFrame(data={'actual' : actual,\n",
        "                            'predict': predict},\n",
        "                      index=actual.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8BSKoVnhyio",
        "colab_type": "text"
      },
      "source": [
        "This function is run with input of the test target series and the predictions made from the test predictor dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIsK0Ubsm25J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b2ce089c-8b19-4caf-a009-5118c1a5759a"
      },
      "source": [
        "actual_predict_pdf = get_actual_predict_pdf(train_test_dict.get('y_test'),\n",
        "                                            get_predict_ser(fit_model,train_test_dict.get('x_test'))\n",
        "                                           ) \n",
        "actual_predict_pdf.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>virginica</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         actual     predict\n",
              "61   versicolor  versicolor\n",
              "91   versicolor  versicolor\n",
              "133   virginica   virginica\n",
              "79   versicolor  versicolor\n",
              "70   versicolor   virginica"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5EGB745iOf5",
        "colab_type": "text"
      },
      "source": [
        "Notice the values and that count of differences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CEXrVKEiVqX",
        "colab_type": "code",
        "outputId": "342c8213-5b05-491d-8fe2-1ef75ae6842c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(    actual_predict_pdf['actual']\n",
        " .ne(actual_predict_pdf['predict'])\n",
        " .sum()\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6der_i5Pi1pI",
        "colab_type": "text"
      },
      "source": [
        "The `get_actual_predict_eval` function takes as input a metric function and a dataframe with columns named `actual` and `predict`. It returns the result of applying the metric to the two columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGUhm8TRr2Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_eval(actual_predict_pdf, metric_function):\n",
        "  return metric_function(actual_predict_pdf['actual'], \n",
        "                         actual_predict_pdf['predict']\n",
        "                        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XWvrgrr-4n",
        "colab_type": "code",
        "outputId": "8de786a3-961e-4a30-b614-9d06c89f693a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "get_actual_predict_eval(actual_predict_pdf=actual_predict_pdf,\n",
        "                        metric_function   =accuracy_score\n",
        "                       )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVk-WDdS7x66",
        "colab_type": "text"
      },
      "source": [
        "## Workflow (essentials)\n",
        "\n",
        "The code cell below collects only the essential commands to implement the workflow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjGfTOmXwTyl",
        "colab_type": "code",
        "outputId": "24ff6c90-2033-4a44-8fce-69f5b3e7dd21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "initial_pdf      = get_iris_pdf()\n",
        "\n",
        "feature_target_pdf = get_feature_target_pdf(pdf               =initial_pdf, \n",
        "                                            transformer_object=IrisFeaTgtPDF()\n",
        "                                           )\n",
        "\n",
        "train_test_dict = get_train_test_dict(pdf        =feature_target_pdf,\n",
        "                                      target_name='target'\n",
        "                                     )\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "fit_model = get_fit_model(estimator_object=LogisticRegression(),\n",
        "                          x_train         =train_test_dict.get('x_train'),\n",
        "                          y_train         =train_test_dict.get('y_train'),\n",
        "                         )\n",
        "\n",
        "actual_predict_pdf = get_actual_predict_pdf(                             \n",
        "                              train_test_dict.get('y_test'),\n",
        "    get_predict_ser(fit_model,train_test_dict.get('x_test'))\n",
        ") \n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "get_actual_predict_eval(actual_predict_pdf,\n",
        "                        accuracy_score\n",
        "                       )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1c1RNrH-_B",
        "colab_type": "text"
      },
      "source": [
        "## Workflow (function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqpsEcPwzt4N",
        "colab_type": "text"
      },
      "source": [
        "### Standard/common functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5AnRZV5RTt",
        "colab_type": "text"
      },
      "source": [
        "The following code cells contains the standard functions defined above (not `get_iris_pdf`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjqgBXU6zIyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_target_pdf(pdf, transformer_object): \n",
        "  return transformer_object.fit(pdf).transform(pdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybrqPvmzCO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_dict(pdf, target_name, **kwargs):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(pdf.drop(columns=target_name),\n",
        "                                                      pdf[target_name], \n",
        "                                                      **kwargs)\n",
        "  return {\n",
        "      'x_train': X_train,\n",
        "      'y_train': y_train,\n",
        "      'x_test' : X_test,\n",
        "      'y_test' : y_test\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNgrpiDLy9u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fit_model(estimator_object, x_train, y_train):\n",
        "  return estimator_object.fit(X=x_train,\n",
        "                              y=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcICL08Ey5aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predict_ser(model, x_test):\n",
        "  return model.predict(X=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub7PyriPy0hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_pdf(actual,predict):\n",
        "  import pandas as pd\n",
        "  return pd.DataFrame(data={'actual' : actual,\n",
        "                            'predict': predict},\n",
        "                      index=actual.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWTMXPcNyly7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_eval(actual_predict_pdf, metric_function):\n",
        "  return metric_function(actual_predict_pdf['actual'], \n",
        "                         actual_predict_pdf['predict']\n",
        "                        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvMmQfk-5d5n",
        "colab_type": "text"
      },
      "source": [
        "The `workflow` function bundles these standard functions together and takes as input the four workflow componets. \n",
        "\n",
        "The result is the evaluation of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clNLYJNiII6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def workflow(initial_pdf,\n",
        "             transformer_object,\n",
        "             estimator_object,\n",
        "             metric_function\n",
        "            ):\n",
        "  feature_target_pdf = \\\n",
        "  get_feature_target_pdf(pdf               =initial_pdf, \n",
        "                         transformer_object=transformer_object\n",
        "                        )\n",
        "\n",
        "  train_test_dict = \\\n",
        "  get_train_test_dict(pdf        =feature_target_pdf,\n",
        "                      target_name='target'\n",
        "                     )\n",
        "\n",
        "  fit_model = \\\n",
        "  get_fit_model(estimator_object=estimator_object,\n",
        "                x_train         =train_test_dict.get('x_train'),\n",
        "                y_train         =train_test_dict.get('y_train'),\n",
        "               )\n",
        "\n",
        "  actual_predict_pdf = \\\n",
        "  get_actual_predict_pdf(train_test_dict.get('y_test'),\n",
        "                         get_predict_ser(fit_model,\n",
        "                                         train_test_dict.get('x_test')\n",
        "                                        )\n",
        "                        ) \n",
        "\n",
        "  return get_actual_predict_eval(actual_predict_pdf,\n",
        "                                 metric_function\n",
        "                                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoBQ3XjCz-_N",
        "colab_type": "text"
      },
      "source": [
        "### Components specific to the iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lWMPfF26INQ",
        "colab_type": "text"
      },
      "source": [
        "The first component is the initial dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYR6yf_0M23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iris_pdf(): \n",
        "  import pandas as pd\n",
        "  from sklearn.datasets import load_iris\n",
        "  iris_features     = load_iris().data\n",
        "  iris_target       = load_iris().target\n",
        "  iris_target_names = load_iris().target_names\n",
        "\n",
        "  iris_feature_columns = [feature_name.replace(' ','_')\n",
        "                                      .replace('(','')\n",
        "                                      .replace(')','') \n",
        "                          for feature_name in load_iris().get('feature_names')]\n",
        "  \n",
        "  iris_features_pdf = pd.DataFrame(data=iris_features,\n",
        "                                   columns=iris_feature_columns\n",
        "                                  )\n",
        "  iris_target_pdf = pd.DataFrame(data={'species': iris_target}) \\\n",
        "                      .replace(to_replace={n:iris_target_names[n]\n",
        "                                           for n in [0,1,2]}) \\\n",
        "                      .astype('object')\n",
        "  iris_pdf = pd.concat([iris_features_pdf, iris_target_pdf],\n",
        "                       axis='columns',\n",
        "                       join='inner')\n",
        "  return iris_pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBm3bMfP6NDX",
        "colab_type": "text"
      },
      "source": [
        "The second component is the transformer class/object that creates the feature-target dataset from the initial dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl5bM5_G0TG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class IrisFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.loc[lambda pdf: pdf.species!='setosa'] \\\n",
        "            .rename(columns={'species':'target'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6DSkM5a6ZBt",
        "colab_type": "text"
      },
      "source": [
        "The last two components are the estimator objectr and the metric function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuYUA7nEIYrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics      import accuracy_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyccQFXW6kE6",
        "colab_type": "text"
      },
      "source": [
        "These components are input to the `workflow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEs5WDsg6hIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4a36f4e6-770d-4c6c-c66e-515d090e225e"
      },
      "source": [
        "workflow(initial_pdf       =get_iris_pdf(),\n",
        "         transformer_object=IrisFeaTgtPDF(),\n",
        "         estimator_object  =LogisticRegression(),\n",
        "         metric_function   =accuracy_score\n",
        "        )\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETDzlw6QTQaP",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - Boston housing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW8Ws4bCJrO5",
        "colab_type": "text"
      },
      "source": [
        "The components of the Boston housing dataset workflow listed in the following three code cells. They are: \n",
        "- the initial dataframe returned by the `get_boston_housing_pdf` function\n",
        "- the transformer class `BostonHousingFeaTgtPDF` that creates the feature-target dataframe\n",
        "- the `LinearRegression()` estimator object\n",
        "- the `mean_absolute_error` metric function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAz076NnBLSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_boston_housing_pdf(): # for boston housing dataset\n",
        "  from sklearn.datasets import load_boston\n",
        "  feature_names = [name.lower() \n",
        "                   for name in load_boston().get('feature_names').tolist()\n",
        "                  ]\n",
        "  features_pdf = pd.DataFrame(data=load_boston().get('data'),\n",
        "                              columns=feature_names\n",
        "                             )\n",
        "  target_pdf = pd.DataFrame(data={'price': load_boston().get('target')}\n",
        "                           )\n",
        "  return pd.concat([features_pdf, target_pdf],\n",
        "                   axis='columns',\n",
        "                   join='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VxHwFT9D8RR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class BostonHousingFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.rename(columns={'price':'target'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QhXXJQJwni3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics      import mean_absolute_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MJ-TJF67iwr",
        "colab_type": "text"
      },
      "source": [
        "These components are input to the `workflow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gROBTx5668RW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fc165cd-0608-42cb-9a7b-820bc6027155"
      },
      "source": [
        "workflow(initial_pdf       =get_boston_housing_pdf(),\n",
        "         transformer_object=BostonHousingFeaTgtPDF(),\n",
        "         estimator_object  =LinearRegression(),\n",
        "         metric_function   =mean_absolute_error\n",
        "        )\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2259902907803664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6-1mm7eCyo1",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - Diamonds dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnUs-K07Boon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_diamonds_pdf():\n",
        "  import pandas as pd\n",
        "  diamonds_file_link = 'https://raw.githubusercontent.com/datalab-datasets/file-samples/master/diamonds.csv'\n",
        "  return pd.read_csv(diamonds_file_link) \\\n",
        "           .drop('Unnamed: 0',\n",
        "                 axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUZ9n2jM8SCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "93ec7283-b34e-4337-df72-37fc9977b375"
      },
      "source": [
        "get_diamonds_pdf().info()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 10 columns):\n",
            "carat      53940 non-null float64\n",
            "cut        53940 non-null object\n",
            "color      53940 non-null object\n",
            "clarity    53940 non-null object\n",
            "depth      53940 non-null float64\n",
            "table      53940 non-null float64\n",
            "price      53940 non-null int64\n",
            "x          53940 non-null float64\n",
            "y          53940 non-null float64\n",
            "z          53940 non-null float64\n",
            "dtypes: float64(6), int64(1), object(3)\n",
            "memory usage: 4.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuSklcV8BnM",
        "colab_type": "text"
      },
      "source": [
        "Add code to the `transform` method of the `DiamondsFeaTgtPDF` class to \n",
        "- drop all of the object columns\n",
        "- rename the `price` column to `target`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I31SwvweCSlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class DiamondsFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.rename(columns={'price':'target'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frGVddQ9CghF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics      import mean_absolute_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRHyZdKa8mzu",
        "colab_type": "text"
      },
      "source": [
        "Supply appropriate values to the `estimator_object`  and `metric_function` parameters. Run the `workflow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhlsmd-S8fnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "fdb424a7-f751-4f8d-a98c-b81b07a1963d"
      },
      "source": [
        "workflow(initial_pdf       =get_diamonds_pdf(),\n",
        "         transformer_object=DiamondsFeaTgtPDF(),\n",
        "         estimator_object  =___, # supply an appriopriate estimator object\n",
        "         metric_function   =___  # supply an appriopriate metric function\n",
        "        )"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d38e71d52b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0mtransformer_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDiamondsFeaTgtPDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mestimator_object\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0m___\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m          \u001b[0mmetric_function\u001b[0m   \u001b[0;34m=\u001b[0m\u001b[0m___\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-33-6b957e751e53>\u001b[0m in \u001b[0;36mworkflow\u001b[0;34m(initial_pdf, transformer_object, estimator_object, metric_function)\u001b[0m\n\u001b[1;32m     14\u001b[0m   fit_model =   get_fit_model(estimator_object=estimator_object,\n\u001b[1;32m     15\u001b[0m                 \u001b[0mx_train\u001b[0m         \u001b[0;34m=\u001b[0m\u001b[0mtrain_test_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0my_train\u001b[0m         \u001b[0;34m=\u001b[0m\u001b[0mtrain_test_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-528fe634a369>\u001b[0m in \u001b[0;36mget_fit_model\u001b[0;34m(estimator_object, x_train, y_train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   return estimator_object.fit(X=x_train,\n\u001b[0m\u001b[1;32m      3\u001b[0m                               y=y_train)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'fit'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPELgd8mRPHG",
        "colab_type": "text"
      },
      "source": [
        "__The End__"
      ]
    }
  ]
}
{"cells":[{"cell_type":"markdown","source":["# Pipelines"],"metadata":{}},{"cell_type":"markdown","source":["Pipelines are sequences of \ntransformers with an optional estimator at the end. \n\nThe entire composite is:\n- a _transformer_ if it does not contain an estimator\n- an _estimator_ if the sequence ends with an estimator\n\nIf a pipeline is:\n- a transformer, then it (the entire pipeline) has a `fit` method and a `transform` method\n- an estimator, then it (the entire pipeline) has a `fit` method and a `predict` method\n\nThe work involved in understanding pipelines is in understanding how the above methods (of the pipeline) are composed of the `fit`, `transform` and `predict` methods of the transformers (and optional estimator) that make up the pipeline. \n\nThis will be demonstrated below in two sections: __Transformer pipelines__ and __Estimator pipelines__."],"metadata":{}},{"cell_type":"markdown","source":["## Reference\n- http://scikit-learn.org/stable/modules/pipeline.html\n- http://scikit-learn.org/stable/data_transforms.html\n- http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n- http://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction\n- http://scikit-learn.org/stable/modules/unsupervised_reduction.html#data-reduction\n- http://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation"],"metadata":{}},{"cell_type":"markdown","source":["## Table of Contents\n1. Setup\n1. Transformer pipelines\n1. Estimator pipelines\n1. Pipelines with train and test datasets"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Setup"],"metadata":{}},{"cell_type":"markdown","source":["Import the `pandas` and `numpy` libraries. In addition, import the `train_test_split` class with which we will create train and test datasets."],"metadata":{}},{"cell_type":"code","source":["import pandas  as pd\nimport numpy   as np\nimport sklearn as sk"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["Display the version numbers of the numpy, pandas and scikit-learn packages:"],"metadata":{}},{"cell_type":"code","source":["print('numpy  ',np.__version__)\nprint('pandas ',pd.__version__)\nprint('sklearn',sk.__version__)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Load the iris dataset to use in the demonstration below. Create datasets for features and the target."],"metadata":{}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\niris_features = load_iris().data\niris_target   = load_iris().target\n(iris_features.shape, \n iris_target.shape\n)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Create train and test datasets from the feature and target datasets."],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(iris_features, iris_target)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["The pipelines below are created with an `Imputer` object, a `MinMaxScaler` object and a `LogisticRegression` classifier object.\nFor details see:\n- `Imputer`: https://bentley.cloud.databricks.com/#notebook/430288\n- `MinMaxScaler`: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n- `LogisticRegression`: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"],"metadata":{}},{"cell_type":"markdown","source":["## 2. Transformer pipelines"],"metadata":{}},{"cell_type":"markdown","source":["A transformer pipeline is sequence of transformers. (It does not contain an estimator.)\n\nFor this demonstration the pipeline will consist of (in this order):\n1. An `Imputer` object that will complete the missing values\n2. A `MinMaxScaler` object that will rescale each column\n\nThis pipeline is created below in `xfm_pipe`."],"metadata":{}},{"cell_type":"markdown","source":["### `fit` and `transform`"],"metadata":{}},{"cell_type":"markdown","source":["Create pipeline and individual transformers."],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline      import Pipeline\nfrom sklearn.preprocessing import Imputer, MinMaxScaler\n\nxfm = Pipeline([\n  ('imputer', Imputer(strategy=\"mean\")),\n  ('scaler',  MinMaxScaler())\n])\nimp = Imputer(strategy=\"mean\")\nsca = MinMaxScaler()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Fit and transform the `x_train` dataset on the individual transformers, in the same order as the pipeline."],"metadata":{}},{"cell_type":"code","source":["x_train_imp      = imp.fit(x_train)    .transform(x_train)\nx_train_imp_sca  = sca.fit(x_train_imp).transform(x_train_imp)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Fit and transform the `x_train` dataset on the entire pipeline."],"metadata":{}},{"cell_type":"code","source":["xfm.fit(x_train)\nx_train_xfm = xfm.transform(x_train)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["Compare the results of these two methods. (They should be the same.)"],"metadata":{}},{"cell_type":"code","source":["np.all(x_train_imp_sca == x_train_xfm)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["They are the same."],"metadata":{}},{"cell_type":"markdown","source":["### `fit` only"],"metadata":{}},{"cell_type":"markdown","source":["Recreate the pipeline and individual transformers."],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline      import Pipeline\nfrom sklearn.preprocessing import Imputer, MinMaxScaler\n\nxfm = Pipeline([\n  ('imputer', Imputer(strategy=\"mean\")),\n  ('scaler',  MinMaxScaler())\n])\nimp = Imputer(strategy=\"mean\")\nsca = MinMaxScaler()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Fit the `x_train` datasets to the individual transformers in the same order as the entire pipeline."],"metadata":{}},{"cell_type":"code","source":["x_train_imp      = imp.fit(x_train).transform(x_train)\nsca.fit(x_train_imp)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Fit the `x_train` dataset on the pipeline."],"metadata":{}},{"cell_type":"code","source":["xfm.fit(x_train)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["Compare the `data_range_` attribute from the last individual transformer and from the pipeline."],"metadata":{}},{"cell_type":"code","source":["(sca                      .data_range_, \n xfm.named_steps['scaler'].data_range_\n)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["They are the same."],"metadata":{}},{"cell_type":"markdown","source":["### `transform` only (`x_train` has already been fit above)"],"metadata":{}},{"cell_type":"markdown","source":["Transform the `x_test` datasets using the individual transformers in the same order as the entire pipeline."],"metadata":{}},{"cell_type":"code","source":["x_test_imp     = imp.transform(x_test)\nx_test_imp_sca = sca.transform(x_test_imp)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["Transform the `x_test` datasets entire pipeline."],"metadata":{}},{"cell_type":"code","source":["x_test_xfm     = xfm.transform(x_test)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["Check whether the two results are the same."],"metadata":{}},{"cell_type":"code","source":["np.all(x_test_imp_sca==x_test_xfm)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["They are."],"metadata":{}},{"cell_type":"markdown","source":["## 3. Estimator pipelines"],"metadata":{}},{"cell_type":"markdown","source":["__TBD__"],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline      import Pipeline\nfrom sklearn.linear_model  import LogisticRegression\nfrom sklearn.preprocessing import Imputer, MinMaxScaler\n\nest = Pipeline([\n  ('imputer', Imputer(strategy=\"mean\")),\n  ('scaler',  MinMaxScaler()),\n  ('logreg',  LogisticRegression())\n])\nimp = Imputer(strategy=\"mean\")\nsca = MinMaxScaler()\nlog = LogisticRegression()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["__The End__"],"metadata":{}}],"metadata":{"name":"5.4 Pipelines","notebookId":409455},"nbformat":4,"nbformat_minor":0}